{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Report:\n",
    "\n",
    "Introduction: The goal of this entire project was to help Interconnect predict which customers were likely to leave, they wanted more customer retention.  An effort was made to figure out which customers would be ready to leave so that the company can take proactive action in keeping them.  Several datasets detailing customer demographics, type of service and contract info were looked at and merged together.  The data was cleaned and machine learning models were made and turned to predict churn.  The performance metric used was AUC-ROC, but Accuracy and Precision amongst others were considered as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed Steps of the Plan used: The four datasets known as contract.csv, personal.csv, internet.csv, and phone.csv were merged using \"customerID\" as a key.  The data types were fixed; missing values were handled and variables that were categorical were encoded.  We analyzed distributions, correlations and churn rates according to the contract and the service type that the customer had.  We used feature engineering, we created new features, such as long term contract flags and we trained and tuned several models by using cross-validation.  A separate test set was held out that was not used until the final evaluation.  We used a limited grid search so we didn't crash the Jupyter environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difficulties Encountered: The dataset had fewer people that were projected to leave than not, but this was solved by applying \"class_weight='balanced_subsample'\" in Random Forest and using AUC-ROC as a robust metric.  There was an issue with feature redundancy and weak predictive signal; this issue was handled by enhancing model performance by introducing engineered interaction and ratio features that capture customer engagement patterns better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Steps for this project: What helped immensely with this project was ensuring that the data for the project was properly prepared and cleaned.  Feature engineering was a big deal as well, the features created provided new predictive power and conducting fair evaluation using cross-validation prevented overfitting.  Making sure the models were turned to optimize AUC-ROC was important and making sure the results were documented transparently was essential as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Model Chosen: The final model that should be chosen, according to the work done, should be the Tuned Random Forest Classifer.  It should give a score of 0.84-0.85 as far as cross-validation; final test score should be around 0.83-0.84.  It's not above 0.88 but the model is stable and fair and it is a transparent take on what can be done as far as helping with customer retention."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
